{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o diretório base como a pasta do projeto\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "\n",
    "DATA_PATH = os.path.join(BASE_DIR, '..', 'data', 'users_behavior.csv')\n",
    "\n",
    "\n",
    "df = pd.read_csv(DATA_PATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_valid, features_test, target_train_valid, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usei test_size=0.2 para separar 20% dos dados para o conjunto de teste. Isso deixa 80% dos dados originais para serem divididos ainda mais entre treinamento e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "   features, target, test_size=0.25, random_state=12345) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelo objetivo ser dividir os 80% de dados restantes em treinamento e validação. Se queremos que a validação seja 20% do total de dados, ela deve ser 25% dos 80% restantes (porque 25% de 80% é igual a 20% do total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 0.942457231726283\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=54321)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predictions_test = model.predict(features_test)\n",
    "accuracy_test = accuracy_score(target_test, predictions_test)\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 0.7076205287713841\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o modelo de Regressão Logística\n",
    "logistic_model = LogisticRegression(random_state=54321)\n",
    "\n",
    "# Treinar o modelo\n",
    "logistic_model.fit(features_train, target_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "predictions_test = logistic_model.predict(features_test)\n",
    "\n",
    "# Avaliar a acurácia do modelo no conjunto de teste\n",
    "accuracy_test = accuracy_score(target_test, predictions_test)\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 0.9471228615863142\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predictions_test = model.predict(features_test)\n",
    "accuracy_test = accuracy_score(target_test, predictions_test)\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo atende ao limite de acurácia estabelecido pelo projeto.\n"
     ]
    }
   ],
   "source": [
    "# Verificando se a acurácia no conjunto de teste é maior que 0,75\n",
    "if accuracy_test > 0.75:\n",
    "    print(\"O modelo atende ao limite de acurácia estabelecido pelo projeto.\")\n",
    "else:\n",
    "    print(\"O modelo não atende ao limite de acurácia. Considere ajustar ou trocar o modelo e/ou hiperparâmetros.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 0.7076205287713841\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o modelo de Regressão Logística\n",
    "logistic_model = LogisticRegression(random_state=12345)\n",
    "\n",
    "# Treinar o modelo\n",
    "logistic_model.fit(features_train, target_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "predictions_test = logistic_model.predict(features_test)\n",
    "\n",
    "# Avaliar a acurácia do modelo no conjunto de teste\n",
    "accuracy_test = accuracy_score(target_test, predictions_test)\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo não atende ao limite de acurácia. Considere ajustar ou trocar o modelo e/ou hiperparâmetros.\n"
     ]
    }
   ],
   "source": [
    "# Verificando se a acurácia no conjunto de teste é maior que 0,75\n",
    "if accuracy_test > 0.75:\n",
    "    print(\"O modelo atende ao limite de acurácia estabelecido pelo projeto.\")\n",
    "else:\n",
    "    print(\"O modelo não atende ao limite de acurácia. Considere ajustar ou trocar o modelo e/ou hiperparâmetros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fica evidente que com a mudança do modelo houve uma brusca mudança na acurácia, tendo, desta forma, o modelo Regressão Logística sido rejeitado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Melhores Hiperparâmetros: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Acurácia no conjunto de validação: 0.8097014925373134\n",
      "Random Forest Acurácia no conjunto de teste: 0.8429237947122862\n"
     ]
    }
   ],
   "source": [
    "# Modelo 1: RandomForestClassifier\n",
    "# Definir o espaço de hiperparâmetros para a busca em grade\n",
    "param_grid_forest = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "grid_search_forest = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=54321),\n",
    "    param_grid_forest,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Executar a busca em grade\n",
    "grid_search_forest.fit(features_train, target_train)\n",
    "\n",
    "# Recuperar o melhor modelo\n",
    "best_forest_model = grid_search_forest.best_estimator_\n",
    "\n",
    "# Avaliar o melhor modelo no conjunto de validação\n",
    "forest_predictions_valid = best_forest_model.predict(features_valid)\n",
    "forest_accuracy_valid = accuracy_score(target_valid, forest_predictions_valid)\n",
    "\n",
    "# Imprimir os melhores hiperparâmetros e a acurácia no conjunto de validação\n",
    "print(f\"Random Forest Melhores Hiperparâmetros: {grid_search_forest.best_params_}\")\n",
    "print(f\"Random Forest Acurácia no conjunto de validação: {forest_accuracy_valid}\")\n",
    "\n",
    "# Avaliar o melhor modelo no conjunto de teste\n",
    "forest_predictions_test = best_forest_model.predict(features_test)\n",
    "forest_accuracy_test = accuracy_score(target_test, forest_predictions_test)\n",
    "\n",
    "# Imprimir a acurácia no conjunto de teste\n",
    "print(f\"Random Forest Acurácia no conjunto de teste: {forest_accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Melhores Hiperparâmetros: {'logisticregression__C': 0.01, 'logisticregression__solver': 'liblinear'}\n",
      "Logistic Regression Acurácia no conjunto de validação: 0.7611940298507462\n",
      "Logistic Regression Acurácia no conjunto de teste: 0.7060653188180405\n"
     ]
    }
   ],
   "source": [
    "# Modelo 2: LogisticRegression\n",
    "\n",
    "# Crie um pipeline que primeiro padroniza os dados e depois aplica a regressão logística\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=54321))\n",
    "\n",
    "\n",
    "# Defina o espaço de hiperparâmetros, incluindo o 'C'\n",
    "param_grid_logistic = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logisticregression__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Inicialize o GridSearchCV com o pipeline\n",
    "grid_search_logistic = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid_logistic,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Execute a busca em grade\n",
    "grid_search_logistic.fit(features_train, target_train)\n",
    "\n",
    "# Recuperar o melhor modelo\n",
    "best_logistic_model = grid_search_logistic.best_estimator_\n",
    "\n",
    "# Avaliar o melhor modelo no conjunto de validação\n",
    "logistic_predictions_valid = best_logistic_model.predict(features_valid)\n",
    "logistic_accuracy_valid = accuracy_score(target_valid, logistic_predictions_valid)\n",
    "\n",
    "# Imprimir os melhores hiperparâmetros e a acurácia no conjunto de validação\n",
    "print(f\"Logistic Regression Melhores Hiperparâmetros: {grid_search_logistic.best_params_}\")\n",
    "print(f\"Logistic Regression Acurácia no conjunto de validação: {logistic_accuracy_valid}\")\n",
    "\n",
    "# Avaliar o melhor modelo no conjunto de teste\n",
    "logistic_predictions_test = best_logistic_model.predict(features_test)\n",
    "logistic_accuracy_test = accuracy_score(target_test, logistic_predictions_test)\n",
    "\n",
    "# Imprimir a acurácia no conjunto de teste\n",
    "print(f\"Logistic Regression Acurácia no conjunto de teste: {logistic_accuracy_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar de não ter visto está função no modulo atual(a função GridSearchCV), achei de suma importancia seu uso para otimizar o modelo de aprendizado de máquina, pois ele automatiza o processo de experimentar várias combinações de hiperparâmetros, avaliando cada uma delas usando validação cruzada. Dessa forma, evitando o uso de força bruta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusões:*\n",
    "\n",
    "Primeiro modelo (Random Forest Classifier):\n",
    "\n",
    "Melhores Hiperparâmetros: O GridSearchCV identificou que a combinação ideal de hiperparâmetros para o RandomForestClassifier é 100 árvores (n_estimators), profundidade máxima de 10 (max_depth), mínimo de uma amostra por folha (min_samples_leaf), e mínimo de duas amostras para divisão de um nó (min_samples_split).\n",
    "Acurácia no Conjunto de Validação: A acurácia de aproximadamente 80.97% no conjunto de validação indica que o modelo é confiável e tem um bom desempenho em dados que não foram usados durante o treinamento.\n",
    "Acurácia no Conjunto de Teste: A acurácia de aproximadamente 84.29% no conjunto de teste mostra que o modelo mantém um bom desempenho em dados não vistos, indicando uma boa capacidade de generalização.\n",
    "Conclusão: O modelo Random Forest Classifier continua sendo um modelo adequado para a tarefa, atendendo aos requisitos do projeto e exibindo boa generalização. A diferença entre a acurácia no conjunto de validação e teste é pequena, o que sugere que não houve sobreajuste significativo.\n",
    "\n",
    "Segundo modelo (Logistic Regression):\n",
    "\n",
    "Melhores Hiperparâmetros: Para a LogisticRegression, o GridSearchCV encontrou que um valor de C de 0.01 com o solver 'liblinear' são os melhores hiperparâmetros.\n",
    "Acurácia no Conjunto de Validação: A acurácia de aproximadamente 76.12% na validação sugere uma performance razoável, mas ainda há espaço para melhorias, especialmente se comparada com a Random Forest.\n",
    "Acurácia no Conjunto de Teste: A acurácia de aproximadamente 70.61% no conjunto de teste está abaixo do limiar de 75% estabelecido pelo projeto, indicando que o modelo pode não ser o mais adequado para esta tarefa específica sem mais ajustes.\n",
    "Conclusão: A Regressão Logística, embora seja um modelo mais simples e rápido de treinar, apresentou uma acurácia inferior ao modelo de Random Forest tanto na validação quanto no teste, o que pode indicar uma menor capacidade de capturar a complexidade dos dados. O baixo valor de C implica em uma forte regularização, o que pode ser necessário para evitar o sobreajuste, mas também pode estar limitando a capacidade do modelo de se ajustar aos dados.\n",
    "\n",
    "*Conclusão geral:* \n",
    "Comparando ambos os modelos, o Random Forest Classifier é superior em termos de acurácia tanto no conjunto de validação quanto no de teste, sugerindo que é um modelo mais robusto para este conjunto de dados. A Regressão Logística pode ser útil para uma interpretação mais direta dos efeitos das características e para casos onde a velocidade de treinamento e predição é crítica, mas pode requerer uma engenharia de características mais cuidadosa e potencialmente mais dados para alcançar uma performance comparável à da Random Forest neste projeto específico.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
